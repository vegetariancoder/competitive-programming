{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Importing Libraries",
   "id": "4a683825422100ca"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-07T22:00:35.498Z",
     "start_time": "2024-12-07T22:00:35.295537Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from Projects.OLIST_SALES.config.config import get_environment_info,get_today_date,check_for_duplicates\n",
    "from pyspark.sql.functions import col,when,count"
   ],
   "id": "b3bdc9a214d36159",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Read Config File",
   "id": "10dd3c301f6482fe"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-07T22:00:37.088745Z",
     "start_time": "2024-12-07T22:00:37.082537Z"
    }
   },
   "cell_type": "code",
   "source": [
    "storage_info = get_environment_info()\n",
    "source_name = \"olist\"\n",
    "storage_account = storage_info[0]\n",
    "landing_container = storage_info[1]\n",
    "raw_container = storage_info[2]\n",
    "load_date = get_today_date()\n",
    "print(load_date)"
   ],
   "id": "ad51453b24200fd3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-07\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Connect to ADLS using SAS Token",
   "id": "4ce43ee32c8042ba"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "4039995b78017ecc"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Data Quality Checks",
   "id": "c57adba02b01205b"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### read the data",
   "id": "a4ec7c1d4c720e62"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-07T22:00:44.455176Z",
     "start_time": "2024-12-07T22:00:44.381156Z"
    }
   },
   "cell_type": "code",
   "source": [
    "customer_df = read_csv_file(path=f\"abfss://{landing_container}@{storage_account}.dfs.core.windows.net/olist_customers_dataset.csv\")\n",
    "geolocation_df = read_csv_file(path=f\"abfss://{landing_container}@{storage_account}.dfs.core.windows.net/olist_geolocation_dataset.csv\")\n",
    "orders_df = read_csv_file(path=f\"abfss://{landing_container}@{storage_account}.dfs.core.windows.net/olist_orders_dataset.csv\")\n",
    "orders_items_df = read_csv_file(path=f\"abfss://{landing_container}@{storage_account}.dfs.core.windows.net/olist_order_items_dataset.csv\")\n",
    "products_df = read_csv_file(path=f\"abfss://{landing_container}@{storage_account}.dfs.core.windows.net/olist_products_dataset.csv\")\n",
    "products_english_df = read_csv_file(path=f\"abfss://{landing_container}@{storage_account}.dfs.core.windows.net/product_category_name_translation.csv\")\n",
    "orders_payment_df = read_csv_file(path=f\"abfss://{landing_container}@{storage_account}.dfs.core.windows.net/olist_order_payments_dataset.csv\")\n",
    "orders_review_df = read_csv_file(path=f\"abfss://{landing_container}@{storage_account}.dfs.core.windows.net/olist_order_reviews_dataset.csv\")"
   ],
   "id": "9f7633a6fed09006",
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'spark' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[6], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m customer_df \u001B[38;5;241m=\u001B[39m \u001B[43mread_csv_file\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpath\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43mf\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mabfss://\u001B[39;49m\u001B[38;5;132;43;01m{\u001B[39;49;00m\u001B[43mlanding_container\u001B[49m\u001B[38;5;132;43;01m}\u001B[39;49;00m\u001B[38;5;124;43m@\u001B[39;49m\u001B[38;5;132;43;01m{\u001B[39;49;00m\u001B[43mstorage_account\u001B[49m\u001B[38;5;132;43;01m}\u001B[39;49;00m\u001B[38;5;124;43m.dfs.core.windows.net/olist_customers_dataset.csv\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m      2\u001B[0m geolocation_df \u001B[38;5;241m=\u001B[39m read_csv_file(path\u001B[38;5;241m=\u001B[39m\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mabfss://\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mlanding_container\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m@\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mstorage_account\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m.dfs.core.windows.net/olist_geolocation_dataset.csv\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m      3\u001B[0m orders_df \u001B[38;5;241m=\u001B[39m read_csv_file(path\u001B[38;5;241m=\u001B[39m\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mabfss://\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mlanding_container\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m@\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mstorage_account\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m.dfs.core.windows.net/olist_orders_dataset.csv\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[0;32m~/Desktop/coding/competitive-programming/Projects/OLIST_SALES/Analysis/config.py:5\u001B[0m, in \u001B[0;36mread_csv_file\u001B[0;34m(path)\u001B[0m\n\u001B[1;32m      4\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mread_csv_file\u001B[39m(path):\n\u001B[0;32m----> 5\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mspark\u001B[49m\u001B[38;5;241m.\u001B[39mread\u001B[38;5;241m.\u001B[39mcsv(path, header\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n",
      "\u001B[0;31mNameError\u001B[0m: name 'spark' is not defined"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Check the null counts",
   "id": "f0b0f83c9879d257"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "datasets = {\n",
    "    \"customer_df\": customer_df,\n",
    "    \"orders_df\": orders_df,\n",
    "    \"orders_items_df\": orders_items_df,\n",
    "    \"products_df\": products_df,\n",
    "    \"orders_payment_df\": orders_payment_df,\n",
    "    \"orders_review_df\": orders_review_df,\n",
    "}\n",
    "\n",
    "for df_name, dataframe in datasets.items():\n",
    "    columns_to_select = []\n",
    "    \n",
    "    # Create null and not-null counts for each column\n",
    "    for c in dataframe.columns:\n",
    "        columns_to_select.append(count(when(col(c).isNull(), c)).alias(f\"{c}_null_count\"))\n",
    "        columns_to_select.append(count(when(col(c).isNotNull(), c)).alias(f\"{c}_not_null_count\"))\n",
    "    \n",
    "    # Calculate results\n",
    "    result = dataframe.select(*columns_to_select)\n",
    "    \n",
    "    # Write the result to CSV\n",
    "    result.coalesce(1).write.format(\"csv\") \\\n",
    "        .option(\"header\", True) \\\n",
    "        .option(\"delimiter\", \",\") \\\n",
    "        .save(f\"abfss://{raw_container}@{storage_account}.dfs.core.windows.net/null_or_not_null/{load_date}/{df_name}\")"
   ],
   "id": "557d08e382ed92fc",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Check If Data Contains Duplicate Records",
   "id": "1a8bf0978997f8da"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "customer_df_columns = ['customer_id','customer_unique_id']\n",
    "orders_df_columns = ['order_id']\n",
    "products_df_columns = ['product_id']\n",
    "        \n",
    "# Check for duplicates in each DataFrame\n",
    "try:\n",
    "    check_for_duplicates(customer_df, customer_df_columns, 'customer_df')\n",
    "    check_for_duplicates(orders_df, orders_df_columns, 'orders_df')\n",
    "    check_for_duplicates(products_df, products_df_columns, 'products_df')\n",
    "    print(\"No duplicates found in the specified columns.\")\n",
    "except Exception as e:\n",
    "    print(str(e))\n",
    "    dbutils.notebook.exit(\"Notebook failed due to duplicates.\")\n"
   ],
   "id": "b50acb8b43828a2d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Copy Data from Landing to Raw",
   "id": "4c8da88fc2c6a4cd"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-07T22:01:14.422527Z",
     "start_time": "2024-12-07T22:01:14.415797Z"
    }
   },
   "cell_type": "code",
   "source": [
    "datasets = {\n",
    "    \"customer\": customer_df,\n",
    "    \"orders\": orders_df,\n",
    "    \"orders_items\": orders_items_df,\n",
    "    \"products\": products_df,\n",
    "    \"orders_payment\": orders_payment_df,\n",
    "    \"orders_review\": orders_review_df\n",
    "}\n",
    "\n",
    "for dataset,dataframe in datasets.items():\n",
    "    dataframe.coalesce(1).write.format(\"parquet\") \\\n",
    "        .option(\"header\", True) \\\n",
    "        .option(\"delimiter\", \",\") \\\n",
    "        .save(f\"abfss://{raw_container}@{storage_account}.dfs.core.windows.net/null_or_not_null/{load_date}/{dataset}/\")"
   ],
   "id": "6c7c2a4812bece9c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "customer_df customer_df\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "befe1cf7349bf814"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
