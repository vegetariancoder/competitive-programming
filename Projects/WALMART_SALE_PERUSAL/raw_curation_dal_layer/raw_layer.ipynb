{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Raw Layer Modeling",
   "id": "6b765375ae8f85f4"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "import libraries and functions.",
   "id": "508b2fb8e4f75778"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from config import spark_session,read_csv_file\n",
    "from pyspark.sql.functions import col, when, count, isnan\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ],
   "id": "64bfc38a43fcd8a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "create spark session",
   "id": "b6418ce34cf01c6d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "spark = spark_session()",
   "id": "806cc9d62f52c5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "read raw data",
   "id": "86bc46fa8214df3d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "raw_df = read_csv_file(path=\"/Users/sahilnagpal/Desktop/coding/competitive-programming/Projects/WALMART_SALE_PERUSAL/input_data/WALMART_SALES_DATA.csv\")",
   "id": "485aef754d332b4a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Sanity Testing",
   "id": "3dce3cd813722fd8"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "capture null value counts",
   "id": "822d6b2d8c35b061"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "raw_df\\\n",
    "    .select([count(when(isnan(c), c)).alias(c) for c in raw_df.columns])\\\n",
    "    .show()"
   ],
   "id": "cf216d940a954c86",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "capture duplicate value",
   "id": "a4416a9279874771"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "raw_df\\\n",
    "    .groupBy(\"Store\",\"Date\",\"Weekly_Sales\",\"Holiday_Flag\",\"Temperature\",\"Fuel_Price\",\"CPI\",\"Unemployment\")\\\n",
    "    .agg(count(\"*\").alias(\"Count\"))\\\n",
    "    .filter(col(\"Count\")>1)\\\n",
    "    .show()"
   ],
   "id": "e2c1dddefeb67b14",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "check data type mismatch",
   "id": "650facedc245da89"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def detect_type_mismatch(spark_df):\n",
    "    mismatches = {}\n",
    "    for column, dtype in spark_df.dtypes:\n",
    "        # Determine the expected data type based on the PySpark dtype\n",
    "        if 'int' in dtype:\n",
    "            expected_type = int\n",
    "        elif 'float' in dtype or 'double' in dtype:\n",
    "            expected_type = float\n",
    "        elif 'string' in dtype:\n",
    "            expected_type = str\n",
    "        else:\n",
    "            continue  # Skipping other data types for simplicity\n",
    "        \n",
    "        # Check for mismatches\n",
    "        mismatches[column] = spark_df.filter(~col(column).cast('string').rlike(get_regex(expected_type)))\n",
    "    \n",
    "    return mismatches\n",
    "\n",
    "def get_regex(expected_type):\n",
    "    if expected_type == int:\n",
    "        return r'^\\d+$'\n",
    "    elif expected_type == float:\n",
    "        return r'^\\d+(\\.\\d+)?$'\n",
    "    elif expected_type == str:\n",
    "        return r'.*'  # Any string is valid\n",
    "    else:\n",
    "        return r'.*'  # Default regex"
   ],
   "id": "262e0f868b066705",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "mismatches = detect_type_mismatch(raw_df)\n",
    "\n",
    "for column, mismatch_df in mismatches.items():\n",
    "    if mismatch_df.count() > 0:\n",
    "        print(f\"Data type mismatches in column '{column}':\")\n",
    "        mismatch_df.show()\n",
    "    else:\n",
    "        print(\"Data type mismatches not found in column '{}':\".format(column))"
   ],
   "id": "4543b21fb2629888",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Sales Trend",
   "id": "b2df85bc2d3d22af"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "raw_pandas_df = raw_df.toPandas()\n",
    "\n",
    "raw_pandas_df['Date'] = pd.to_datetime(raw_pandas_df['Date'], format='%d-%m-%Y')\n",
    "\n",
    "# Step 5: Set the 'Date' column as the index\n",
    "raw_pandas_df.set_index('Date', inplace=True)\n",
    "\n",
    "# Step 6: Convert relevant columns to numeric types\n",
    "numeric_columns = ['Weekly_Sales', 'Holiday_Flag', 'Temperature', 'Fuel_Price', 'CPI', 'Unemployment']\n",
    "raw_pandas_df[numeric_columns] = raw_pandas_df[numeric_columns].apply(pd.to_numeric)\n",
    "\n",
    "# Step 7: Plot the data using Matplotlib\n",
    "raw_pandas_df['Weekly_Sales'].plot(style='k.')\n",
    "plt.show()\n"
   ],
   "id": "51b8512a16389f5f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "raw_df\\\n",
    "    .groupBy(col(\"Holiday_Flag\"))\\\n",
    "    .agg(count(\"*\").alias(\"Count\"))\\\n",
    "    .withColumn(\"Holiday_Flag\", when(col(\"Holiday_Flag\") == 1, \"Holiday\").otherwise(\"Working\"))\\\n",
    "    .show()"
   ],
   "id": "b5b450357b33d116",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "482dfd366642c05d",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
